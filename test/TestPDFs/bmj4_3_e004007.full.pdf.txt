

machine-learning prediction of cancer survival: a retrospective study using electronic administrative records and a cancer registry sunil gupta,1 truyen tran,1,2 wei luo,1 dinh phung,1 richard lee kennedy,3 adam broad,4 david campbell,4 david kipp,4 madhu singh,4 mustafa khasraw,3,4 leigh matheson,5 david m ashley,3,4,5 svetha venkatesh1 to cite: gupta s, tran t, luo w, et al. machine- learning prediction of cancer survival: a retrospective study using electronic administrative records and a cancer registry. bmj open 2014;4:e004007. doi:10.1136/bmjopen-2013- 004007 ▸ additional material is available. to view please visit the journal (http://dx.doi.org/ 10.1136/bmjopen-2013- 004007). received 13 september 2013 revised 17 february 2014 accepted 21 february 2014 for numbered affiliations see end of article. correspondence to professor svetha venkatesh; svetha.venkatesh@deakin. edu.au abstract objectives: using the prediction of cancer outcome as a model, we have tested the hypothesis that through analysing routinely collected digital data contained in an electronic administrative record (ear), using machine-learning techniques, we could enhance conventional methods in predicting clinical outcomes. setting: a regional cancer centre in australia. participants: disease-specific data from a purpose-built cancer registry (evaluation of cancer outcomes (eco)) from 869 patients were used to predict survival at 6, 12 and 24 months. the model was validated with data from a further 94 patients, and results compared to the assessment of five specialist oncologists. machine-learning prediction using eco data was compared with that using ear and a model combining eco and ear data. primary and secondary outcome measures: survival prediction accuracy in terms of the area under the receiver operating characteristic curve (auc). results: the eco model yielded aucs of 0.87 (95% ci 0.848 to 0.890) at 6 months, 0.796 (95% ci 0.774 to 0.823) at 12 months and 0.764 (95% ci 0.737 to 0.789) at 24 months. each was slightly better than the performance of the clinician panel. the model performed consistently across a range of cancers, including rare cancers. combining eco and ear data yielded better prediction than the eco-based model (aucs ranging from 0.757 to 0.997 for 6 months, aucs from 0.689 to 0.988 for 12 months and aucs from 0.713 to 0.973 for 24 months). the best prediction was for genitourinary, head and neck, lung, skin, and upper gastrointestinal tumours. conclusions:machine learning applied to information from a disease-specific (cancer) database and the ear can be used to predict clinical outcomes. importantly, the approach described made use of digital data that is already routinely collected but underexploited by clinical health systems. introduction over the past two decades, there has been an explosion in the use of digital footprints to monitor and predict human behaviours. the source of data used for this purpose is our online use of the internet, the emails we send and transactions we make. analysis of these footprints through machine-learning techniques (mlt) has been exploited in the public domain by government and business to predict behaviours and inform investment decisions. in research, mlt have also been used to analyse gene expression data1 2 and for medical image analysis.3 4 however to date, there has been little exploration of these methodologies in the clinical setting. we hypothesised that mlt may offer a para- digm shift in clinical medicine that can address core issues with large and complex data sets. these techniques offer the poten- tial to derive adaptive systems from diverse data sets, discover latent connections between data items and to predict outcomes. most hospitals routinely collect large digital electronic administrative records (ear). these are primarily used for organisational ﬁnancial management. historically, they have not been used extensively for clinical or research purposes. if these large data sets are able to be exploited using mlt, it may open the way to optimise the use of collected admin- istrative data to assist in predicting patients’ outcome, planning individualised patient care, monitoring resource utilisation and improving strengths and limitations of this study ▪ this is the first study using machine learning of administrative and registry data for cancer sur- vival prediction. ▪ a single prognosis model is produced across all cancers, improving prediction accuracy on rare cancers. ▪ this is a retrospective study in a single centre. gupta s, tran t, luo w, et al. bmj open 2014;4:e004007. doi:10.1136/bmjopen-2013-004007 1 open access research


institutional performance.5 6 the accurate assessment of comorbid status would improve assessment of prognosis and guide treatment decisions.7–10 other important infor- mation that may be contained or inferred from an ear includes geographical and demographic data, socio- economic status and history of healthcare facility utilisation.2 11 12 in this study, using cancer outcome prediction as a model, we wished to test the hypothesis that routinely collected digital health data, if analysed by state-of-the-art, validated, mlt could be used to assist conventional tools in predicting clinical outcomes. accurate prediction of survival in patients with cancer remains a challenge due to the ever-increasing hetero- geneity and complexity of cancer, treatment options and patient populations. if achieved, reliable predictions could assist personalised care and treatment, and improve institutional performance in cancer manage- ment. in current practice, clinicians use data collected at the bedside in consultations, medical records or purpose-built cancer registries to aid prognostication and decision-making. the notion of using mlt to predict cancer prognosis from clinical and pathological data is not a new one.13 14 however, with the advent of more sophisticated and better validated techniques, not only is more accurate prediction possible, but the range of data incorporated into decision aids can be increased.15–17 the need to improve cancer care systems by creating linkages between registries and epidemiological surveillance through analysis of complex and large clinical databases has recently been highlighted.18 19 in this study, we tested the capability of mlt to predict patient outcomes in a heterogeneous cohort of patients with cancer. we have interrogated two data sets: ﬁrst, a purpose-built cancer-speciﬁc registry (evaluation of cancer outcomes, eco, from victorian cancer outcomes network in partnership with the barwon south western regional integrated cancer service) con- taining demographic and tumour-related data items according to an australian nationally agreed protocol; and second, a hospital digital data set containing infor- mation about the patient’s previous admissions and pre- sentations (ear). finally, in a test group of 94 patients, we examined the performance of machine-learning methods in aiding a panel of expert clinicians in predict- ing patient survival. patients and methods study design this is a retrospective study using the ear and a specia- lised cancer registry (eco) from barwon health, the only public tertiary institution in a region of australia with more than 350 000 residents. with a uniﬁed hos- pital identity number in use across the region, barwon health’s ear provides a single point of access for infor- mation on patient encounters with the health system, including hospitalisations, ed visits, medications and treatments. in addition, the andrew love cancer centre at barwon health has a specialised cancer registry called eco, which captures clinical data for patients in the region. eco records information on demographics, primary tumour and metastatic tumour, cancer stage, tumour size, lymph nodes and breast tumour-speciﬁc information. treatment type, outcomes, including death, and recurrence information (primary and metastatic) are also recorded. box 1 shows the variables used for survival prediction. the cohort for this study consists of 963 patients identiﬁed in eco who were ﬁrst diagnosed in year 2009. the study completion date was 31 october 2012; therefore, all patients had at least 2 year and 10 months follow-up. among these patients, 736 patients also had records in the ear. analyses the analyses centred on predicting cancer survival since the date of diagnosis, deﬁned as the date of tumour resection. each patient was a unit of observation in the predictive problem: patient data collected prior to the diagnosis date were used to construct the independent variables; survival status in a period following the assess- ment was the dependent variable. two analyses were per- formed: the ﬁrst compared survival prediction made by machine-learning models and the clinician panel, based on only information from eco. the second analysis evaluated the added discriminative power provided by ear, by comparing the best machine-learning models using three sets of predicting variables: variables from box 1 evaluation of cancer outcomes (eco) variables used for survival prediction patient demographics post code gender age tumour characteristics primary site (in international classification of diseases (icd)-10 code) tumour stream morphology (in icd-o-3 code) histological grade metastatic sites most valid basis of diagnosis performance status diagnosis stage basis (pathological or clinical) stage (tnm) tumour size nodes taken positive nodes breast cancer related variables oestrogen receptor progesterone receptor human epidermal growth factor receptor 2 (her2) 2 gupta s, tran t, luo w, et al. bmj open 2014;4:e004007. doi:10.1136/bmjopen-2013-004007 open access


eco (box 1), variables from ear (see online supple- mentary appendix) and the union of the two. although a survival analysis model (eg, a proportional hazards model20) is commonly used in modelling risk factors, such models are not designed to predict events. in this study, survival was directly modelled using classiﬁ- cation models to optimise prediction accuracy. comparing predictions by machine-learning models and clinician in the ﬁrst analysis, all 963 patients in the eco registry were randomly divided into a derivation cohort of 869 patients and a validation cohort of 94 patients (table 1). to collect clinician prediction, patients in the validation cohort were assigned to a panel of ﬁve oncologists for survival prediction. for each patient, the oncologist was asked to estimate the survival probabilities based on the independent variables in box 1. all clinicians estimated the patient’s survival status by producing a probability for each of the three time periods—6 months, 1 year and 2 years. when making this assessment, the clinicians did not have knowledge of the treatment type offered or given to the patient. three machine-learning models were trained on the derivation cohort using the same set of independent variables, one for each prediction period. each of the machine-learning models was an ensemble of 400 support vector machines (svms)21 with linear kernel (ie, the output of the model was the average of 400 svm outputs in platt’s a posteriori prob- abilities22). ensemble was used to control the variability introduced by l1 feature selection. each of the svms was trained using a random 80% subsampling (without replacement) of the derivation cohort.23 the soft margin parameter (c) of svm was selected through cross-validation. two measures were taken to improve the training process. first, to compensate for the imbal- ance between the two outcomes (there were more survivals than deaths), we oversampled the non-surviving cases by 50% in each training subsample. next, variable selection was performed through ﬁtting a generalised linear model with elastic net regularisation24 (α parameter set to 0.1 and λ parameter selected using ﬁvefold internal cross-validation), and variables with zero coefﬁcients were removed. after the machine- learning models were constructed, they were applied to predict survival probabilities for each patient in the val- idation cohort. the clinician and model predictions were validated with the actual outcomes in the eco registry. prediction performance was measured using the area under the receiver operating characteristic curve (auc), also known as the c-statistic,25 and 95% cis of aucs were computed using 1000 bootstrap samples of validation cohort. comparing discriminative information from specialised registry and routine data the second analysis compared the discriminative power of two data sources (eco and ear). in this analysis, clinician predictions were not solicited. among the 869 patients in the derivation subset of cohort 1, only 664 had records in the ear and these patients were included in the second analysis (cohort 2, table 1). survival prediction models were derived based on three sets of independent variables: (1) independent variables from ear (ear only); (2) independent variables from eco (eco only) and (3) the union of the two sets (ear+eco). similar to the previous analysis, the models were trained using 400 random subsamples com- prising 80% data of the cohort 2, and the modelling process was identical. however, the models were evalu- ated not using the validation cohort. instead, for each 80% subsample, the remaining 20% was used to compute the auc and its 95%ci. table 1 characteristics of derivation and validation cohorts cohort 1: eco cohort 2: eco and ear (n=664)derivation (n=869) validation (n=94) age (sd) 67.6 (14.6) 68.4 (13.6) 66.3 (14.9) gender: male 487* 48 381 tumour stream genitourinary 172 21 135 colorectal 140 14 115 lung 121 18 96 breast 122 15 74 haematological 99 7 85 upper gastrointestinal 83 9 57 skin 36 1 28 head and neck 35 0 30 gynaecological 19 4 17 cns 15 1 9 unknown primary 38 9 26 *two unspecified. cns, central nervous system; ear, electronic administrative records; eco, evaluation of cancer outcomes. gupta s, tran t, luo w, et al. bmj open 2014;4:e004007. doi:10.1136/bmjopen-2013-004007 3 open access


the wilcoxon rank-sum test was applied to answer the following comparison problems: 1. does eco only provide more discriminative power than ear only? 2. does ear+eco provide more discriminative power than ear only? 3. does ear+eco provide more discriminative power than eco only? details of the machine-learning model and the pre- dictor variables can be found in the online supplemen- tary appendix. results the cohorts for the two analyses are summarised in table 1. the comparison between the algorithmic pre- dictions and the clinician predictions are summarised in table 2. the model had comparable performance to that of the clinicians, with the performance of the machine-learning model marginally better (auc ranging from 0.76 to 0.87) than that of the clinicians (auc ranging from 0.75 to 0.79) for all three prediction periods. this similarity in accuracy between algorithmic predictions and the clinician predictions was observed across different cancer types. consider the predictions for 6-month survival. of 15 breast cancer cases, the clinicians made 15 correct predictions and the algo- rithm made 14; of 18 lung cancer cases, the clinicians made 13 correct predictions and the algorithm made 14; of 7 haematological cases, the clinicians and the algorithm made all predictions correctly. similar results were observed on 12-month and 24-month survival pre- dictions for different cancers. prediction of 6-month survival using the three models is shown in table 3. there were no deaths from breast cancer during this period. comparing the eco model with the ear model, aucs were comparable for colo- rectal, genitourinary, haematological, head and neck, and skin tumours. the ear model was signiﬁcantly better (p<0.05) for rare tumours, central nervous system (cns), upper gastrointestinal and unassigned primary source tumours. for each tumour type, the model using eco and ear data yielded similar or better perform- ance than the models using information from only one of the two databases. aucs for the combined model ranged from 0.76 to 1.0. the combined data model showed particularly improved performance over eco data (p < 0.05) for all tumour streams except breast and cns tumours. data for 12-month survival prediction is shown in table 4. cancer-speciﬁc eco data yielded better predic- tion than ear data (p<0.05) for gynaecological, haem- atological, lung, skin and unknown primary cancers. otherwise, eco and ear models yielded generally similar results. the model using combined data per- formed better than ear (p<0.05) for all tumour streams other than cns, head and neck and upper gastrointes- tinal tumours. the model using combined data was better than (p<0.05) eco for all cancers except breast, cns, gynaecological and haematological cancers. table 5 shows data for 24-month survival prediction by the three models. the eco model yielded superior pre- diction (p<0.05) to the ear model for breast, table 2 performance of survival prediction: comparison between machine-learning method and clinicians survival period auc (95% ci) clinician panel machine-learning model 6 months 0.79 (0.76 to 0.81) 0.87 (0.85 to 0.89) 1 year 0.79 (0.76 to 0.81) 0.80 (0.77 to 0.82) 2 years 0.75 (0.73 to 0.78) 0.76 (0.74 to 0.79) auc, area under the receiver operating characteristic curve. table 3 prediction performance of machine-learning algorithms: 6-month survival cancer type area under roc curve (95% ci) ear only eco only ear+eco genitourinary 0.81 (0.77 to 0.85) 0.82 (0.78 to 0.86) 0.88 (0.85 to 0.91)*,† colorectal 0.84 (0.80 to 0.88) 0.85 (0.81 to 0.89) 0.88 (0.84 to 0.91)*,† lung 0.71 (0.67 to 0.76) 0.73 (0.69 to 0.77)* 0.77 (0.73 to 0.82)*,† breast no deaths in the period haematological 0.73 (0.68 to 0.79) 0.74 (0.69 to 79) 0.76 (0.71 to 0.81) upper gastrointestinal 0.74 (0.69 to 0.78) 0.64 (0.60 to 69) 0.84 (0.80 to 0.87)† skin 0.84 (0.77 to 0.90) 0.85 (0.79 to 91) 0.91 (0.86 to 0.96)*,† head and neck 0.66 (0.61 to 0.71) 0.70 (0.64 to 75) 0.77 (0.72 to 0.82)*,† gynaecological 0.97 (0.94 to 0.99) 0.99 (0.98 to 1)* 1 (0.99 to 1)* cns 0.89 (0.85 to 0.94) 0.84 (0.78 to 0.90) 0.82 (0.77 to 0.88) unknown primary 0.92 (0.89 to 0.95) 0.79 (0.75 to 0.84) 0.90 (0.87 to 0.93)*,† *significantly greater than ear only. †significantly greater than eco only. cns, central nervous system; ear, electronic administrative records; eco, evaluation of cancer outcomes; roc, receiver operating characteristic. 4 gupta s, tran t, luo w, et al. bmj open 2014;4:e004007. doi:10.1136/bmjopen-2013-004007 open access


genitourinary, gynaecological, lung, skin and unknown primary cancers, while the ear model was superior to the eco model for haematological and head and neck tumours. once more, the model that performed the best was that derived from eco and ear data with aucs ranging from 0.71 to 0.97 across the range of cancers and particularly enhanced performance for all cancers except breast, colorectal, gynaecological and unknown primary tumours compared with the eco. in summary, over all time periods, the performance of the combined model was better than eco (p<0.05) for genitourinary, head and neck, lung, skin, and upper gastrointestinal tumours. one of the key advantages of using mlt is that it can combine the large number of non-clinical factors with the few clinical risk factors. in this study, the model selected most of the known clinical risk factors including patient age, cancer staging, performance status and tumour size. in addition, it also found some useful non-clinical risk factors, including the type of the last hospital admission (emergency vs elective), the frequency of ed visits within the previous 3 and 6 months (related to cancer and other medical conditions). discussion in this study, using cancer outcome prediction as a model, we wished to test the hypothesis that routinely collected digital health data, if analysed by mlt, could be used to assist conventional tools in predicting clinical outcomes. applying machine learning to data from the ear alone predicted clinical outcomes with reasonable accur- acy. using the purpose-built eco data set, the predictive tool also performed well across a broad range of cancer types, and in both cases the predictive accuracies were at least as good as that of a panel of ﬁve expert clinicians. importantly, a predictive tool derived from the purpose- built clinical registry and administrative data had even greater predictive ability. table 4 prediction performance of machine-learning algorithms: 12-month survival cancer type area under roc curve (95% ci) ear only eco only ear+eco genitourinary 0.79 (0.75 to 0.83) 0.79 (0.75 to 0.83) 0.84 (0.80 to 0.87)*,† colorectal 0.82 (0.78 to 0.86) 0.83 (0.79 to 0.86) 0.87 (0.83 to 0.90)*,† lung 0.73 (0.69 to 0.77) 0.78 (0.73 to 0.82)* 0.82 (0.78 to 0.86)*,† breast 0.71 (0.65 to 0.78) 0.90 (0.86 to 0.94) 0.92 (0.89 to 0.96)* haematological 0.63 (0.59 to 0.68) 0.70 (0.66 to 0.75)* 0.69 (0.64 to 0.74)* upper gastrointestinal 0.62 (0.57 to 0.66) 0.70 (0.65 to 0.74)* 0.72 (0.68 to 0.76)* skin 0.76 (0.71 to 0.88) 0.89 (0.85 to 0.93)* 0.93 (0.90 to 0.96)* head and neck 0.77 (0.73 to 0.88) 0.68 (0.63 to 0.73) 0.79 (0.75 to 0.84)† gynaecological 0.95 (0.92 to 0.97) 1 (1 to 1)* 0.99 (0.98 to 1)* cns 0.66 (0.58 to 0.73) 0.68 (0.61 to 0.76) 0.69 (0.63 to 0.76) unknown primary 0.87 (0.84 to 0.91) 0.81 (0.77 to 0.85) 0.88 (0.84 to 0.91) *significantly greater than ear only. †significantly greater than eco only. cns, central nervous system; ear, electronic administrative records; eco, evaluation of cancer outcomes; roc, receiver operating characteristic. table 5 prediction performance of machine-learning algorithms: 24-month survival area under the roc curve (auc) cancer type ear only eco only ear+eco genitourinary 0.73 (0.69 to 0.78) 0.84 (0.81 to 0.88)* 0.86 (0.82 to 0.89)*,† colorectal 0.76 (0.72 to 0.80) 0.76 (0.72 to 0.80) 0.76 (0.72 to 0.80) lung 0.74 (0.69 to 0.78) 0.78 (0.73 to 0.82)* 0.82 (0.79 to 0.86)*,† breast 0.67 (0.61 to 0.73) 0.86 (0.82 to 0.90)* 0.88 (0.84 to 0.92)* haematological 0.73 (0.68 to 0.77) 0.70 (0.66 to 0.75) 0.80 (0.76 to 0.84)*,† upper gastrointestinal 0.81 (0.77 to 0.85) 0.77 (0.72 to 0.81) 0.87 (0.83 to 0.9)*,† skin 0.71 (0.65 to 0.76) 0.85 (0.8 to 0.89)* 0.94 (0.92 to 0.97)*,† head and neck 0.74 (0.7 to 0.78) 0.66 (0.51 to 0.61) 0.71 (0.67 to 0.76)† gynaecological 0.96 (0.94 to 0.99) 0.99 (0.98 to 1)* 0.97 (0.95 to 0.99) cns 0.83 (0.78 to 0.89) 0.87 (0.82 to 0.93) 0.96 (0.93 to 0.99)*,† unknown primary 0.74 (0.7 to 0.79) 0.78 (0.74 to 0.82)* 0.8 (0.76 to 0.84)* *significantly greater than ear only. †significantly greater than eco only. cns, central nervous system; ear, electronic administrative records; eco, evaluation of cancer outcomes; roc, receiver operating characteristic. gupta s, tran t, luo w, et al. bmj open 2014;4:e004007. doi:10.1136/bmjopen-2013-004007 5 open access


the wealth of administrative data contained in the ear includes information on comorbid conditions and previ- ous clinic and hospital attendances as well as a drug history. there is considerable potential to use this data to improve clinical care across a spectrum of diseases.5 6 most patients in the study were followed up for 3 years, which may not be adequate to capture all onco- logical outcomes, especially for those cancers with low mortality rate. we have designed this study as retrospect- ive and in a single centre; it will be of major interest to observe how it performs in a variety of settings. the number of cases used to assess performance of the models is relatively small. the strengths include the comparison of machine-learning tools with expert clin- ical opinion and the fact that very detailed and well- validated data was available both directly related to the cancer and that contained in the ear. the generic nature of this approach makes it unnecessary to gener- ate separate predictive models for different types of cancer. this was a particular advantage for rarer forms of cancer where predications using more conventional methods are very challenging. predictive tools derived from clinical data items have considerable potential to improve clinical care, but must be suitably optimised and shown to perform equally well in diverse clinical settings.26 27 clinical databases have become more widely available and increasingly complex in recent years. the extent and complexity of data available to clinicians means that novel approaches to managing data and supporting clinical decisions are needed. machine-learning approaches can not only cope with complex data sets, but also adapt in real time and across different clinical settings. the approach used in this study offers superior per- formance to previous machine-learning approaches in predicting cancer survival.13–17 previous models have been derived for single cancer types, or for a limited range of cancers. the model described here performed well across a wide range of cancers. one advantage of this generic approach may be the ability to predict out- comes in less common cancers where limited data might preclude development of speciﬁc models. the fact that our model derived from administrative and cancer- related data performed slightly better than a panel of expert clinicians validates the potential utility of the model and suggests that it may be useful in assessing quality of care and also in settings where specialist care is not available. an alternative approach to borrow infor- mation across different cancer types is called multitask learning. we are currently exploring this approach as well. clinical outcomes in any illness are determined by speciﬁc factors related to the illness itself and also by the patient’s general state of health and by the presence of other chronic medical conditions often coded in an ear if the individual trafﬁcs the health service.7–10 as well, a particularly novel and important aspect of the use of historical data from the ear in machine learning is that it effectively captures the healthcare institution’s current and previous performance. these data can be applied to any individual entering the system with a newly diagnosed cancer, as we have modelled here. as well, they could also be used for quality and perform- ance monitoring. in conclusion, machine learning applied to informa- tion from a disease-speciﬁc (cancer) database and the ear can be used to predict outcomes. improved predic- tion of outcome has the potential to help clinicians make more meaningful decisions about treatment and to assist with planning of future social and care needs. most importantly, the approach described makes use of digital data that is already routinely collected but under- exploited by clinical health systems. author affiliations 1centre for pattern recognition and data analytics, deakin university, geelong, victoria, australia 2department of computing, curtin university, perth, western australia, australia 3school of medicine, deakin university, geelong, victoria, australia 4andrew love cancer centre, barwon health, geelong, victoria, australia 5barwon southwest integrated cancer service, geelong, victoria, australia contributors all authors of this research paper have directly participated in the planning, execution or analysis of the study. all authors of this paper have read and approved the final version submitted. funding this research received no specific grant from any funding agency in the public, commercial or not-for-profit sectors. competing interests none. ethics approval ethics approval was obtained from the hospital and research ethics committee at barwon health (number 12/83). deakin university has reciprocal ethics authorisation with barwon health. provenance and peer review not commissioned; externally peer reviewed. data sharing statement no additional data are available. open access this is an open access article distributed in accordance with the creative commons attribution non commercial (cc by-nc 3.0) license, which permits others to distribute, remix, adapt, build upon this work non- commercially, and license their derivative works on different terms, provided the original work is properly cited and the use is non-commercial. see: http:// creativecommons.org/licenses/by-nc/3.0/ references 1. zhao x, rodland ea, sorlie t, et al. combining gene signatures improves prediction of breast cancer survival. plos one 2011;6: e17845. 2. chang cm, su yc, lai ns, et al. the combined effect of individual and neighborhood socioeconomic status on cancer survival rates. plos one 2012;7:e44325. 3. li c, zhang s, zhang h, et al. using the k-nearest neighbor algorithm for the classification of lymph node metastasis in gastric cancer. comput math methods med 2012;2012:876545. 4. huang ml, hung yh, lee wm, et al. usage of case-based reasoning, neural network and adaptive neuro-fuzzy inference system classification techniques in breast cancer dataset classification diagnosis. j med syst 2012;36:407–14. 5. appari a, eric johnson m, anthony dl. meaningful use of electronic health record systems and process quality of care: evidence from a panel data analysis of u.s. acute-care hospitals. health serv res 2013;48:354–75. 6. fitzhenry f, murff hj, matheny me, et al. exploring the frontier of electronic health record surveillance: the case of postoperative complications. med care 2013;51:509–16. 6 gupta s, tran t, luo w, et al. bmj open 2014;4:e004007. doi:10.1136/bmjopen-2013-004007 open access


7. lund l, borre m, jacobsen j, et al. impact of comorbidity on survival of danish prostate cancer patients, 1995–2006: a population-based cohort study. urology 2008;72:1258–62. 8. tetsche ms, norgaard m, jacobsen j, et al. comorbidity and ovarian cancer survival in denmark, 1995–2005: a population-based cohort study. int j gynecol cancer 2008;18:421–7. 9. lieffers jr, baracos ve, winget m, et al. a comparison of charlson and elixhauser comorbidity measures to predict colorectal cancer survival using administrative health data. cancer 2011;117:1957–65. 10. braithwaite d, moore dh, satariano wa, et al. prognostic impact of comorbidity among long-term breast cancer survivors: results from the lace study. cancer epidemiol biomarkers prev 2012;21: 1115–25. 11. jones le, doebbeling cc. beyond the traditional prognostic indicators: the impact of primary care utilization on cancer survival. j clin oncol 2007;25:5793–9. 12. sant m, minicozzi p, allemani c, et al. regional inequalities in cancer care persist in italy and can influence survival. cancer epidemiol 2012;36:541–7. 13. burke hb, goodman ph, rosen db, et al. artificial neural networks improve the accuracy of cancer survival prediction. cancer 1997;79:857–62. 14. lundin m, lundin j, burke hb, et al. artificial neural networks applied to survival prediction in breast cancer. oncology 1999;57:281–6. 15. manilich ea, kiran rp, radivoyevitch t, et al. a novel data-driven prognostic model for staging of colorectal cancer. j am coll surg 2011;213:579–88, 588.e1–2. 16. gao p, zhou x, wang zn, et al. which is a more accurate predictor in colorectal survival analysis? nine data mining algorithms vs. the tnm staging system. plos one 2012;7:e42015. 17. kim w, kim ks, lee je, et al. development of novel breast cancer recurrence prediction model using support vector machine. j breast cancer 2012;15:230–8. 18. johnson cj, weir hk, fink ak, et al. accuracy of cancer mortality study group. the impact of national death index linkages on population-based cancer survival rates in the united states. cancer epidemiol 2013;37:20–8. 19. khoury mj, lam tk, ioannidis jp, et al. transforming epidemiology for 21st century medicine and public health. cancer epidemiol biomarkers prev 2013;22:508–16. 20. cox dr, oakes d. analysis of survival data. crc press, 1984. 21. cortes c, vapnik v. support vector machine. mach learn 1995;20:273–97. 22. lin h-t, lin c-j, weng rc. a note on platt’s probabilistic outputs for support vector machines. mach learn 2007; 68:267–76. 23. politis d, romano j, wolf m. subsampling. new york: springer-verlag, 1999. 24. friedman j, hastie t, tibshirani r. regularization paths for generalized linear models via coordinate descent. j stat softw 2010;33:1–22. 25. hastie t, tibshirani r, friedman j, et al. the elements of statistical learning: data mining, inference and prediction. math intelligencer 2005;27:83–5. 26. chen hc, kodell rl, cheng kf, et al. assessment of performance of survival prediction models for cancer prognosis. bmc med res methodol 2012;12:102. 27. chen hc, chen jj. assessment of reproducibility of cancer survival risk predictions across medical centers. bmc med res methodol 2013;13:25. gupta s, tran t, luo w, et al. bmj open 2014;4:e004007. doi:10.1136/bmjopen-2013-004007 7 open access
